{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appending torchvision reference scripts for detection to path for importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('torchvisionreferencedetection/torchvision-reference-derection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing pycocotools for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -octr (/home/nikkokks/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -octr (/home/nikkokks/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pycocotools in /home/nikkokks/.local/lib/python3.8/site-packages (2.0.4)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from pycocotools) (3.7.2)\n",
      "Requirement already satisfied: numpy in /home/nikkokks/.local/lib/python3.8/site-packages (from pycocotools) (1.22.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nikkokks/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikkokks/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/nikkokks/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (6.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikkokks/anaconda3/envs/doctr3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -octr (/home/nikkokks/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -octr (/home/nikkokks/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from engine import train_one_epoch, evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_csv_path = \"../input/yolo-animal-detection-small/train.csv\"\n",
    "test_csv_path = \"../input/yolo-animal-detection-small/test.csv\"\n",
    "train_images = \"../input/yolo-animal-detection-small/yolo-animal-detection-small/train\"\n",
    "test_images = \"../input/yolo-animal-detection-small/yolo-animal-detection-small/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(train_csv_path)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(test_csv_path)\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_csv[\"class\"].unique()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding classes to integers.\n",
    "\n",
    "- 0 is for background by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelMap:\n",
    "    def __init__(self, categories):\n",
    "        self.map_dict = {}\n",
    "        self.reverse_map_dict={}\n",
    "        for i, cat in enumerate(categories):\n",
    "            self.map_dict[cat] = i + 1\n",
    "            self.reverse_map_dict[i] = cat\n",
    "    def fit(self, df, column):\n",
    "        df[column] = df[column].map(self.map_dict)\n",
    "        return df\n",
    "    def inverse(self, df, column):\n",
    "        df[column] = df[column].map(self.map_dict)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = LabelMap(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = label_map.fit(train_csv, \"class\")\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = label_map.fit(test_csv, \"class\")\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, image_path, categories, transforms=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.df = df\n",
    "        self.image_path = image_path\n",
    "        self.categories = categories\n",
    "        self.images = self.df[\"filename\"].unique()\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_file = os.path.join(self.image_path, self.images[idx])\n",
    "        img = cv2.imread(image_file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "        image_data = self.df[self.df['filename'] == self.images[idx]]\n",
    "        labels = torch.as_tensor(image_data[\"class\"].values, dtype=torch.int64)\n",
    "        xmins = image_data[\"xmin\"].values\n",
    "        ymins = image_data[\"ymin\"].values\n",
    "        xmaxs = image_data[\"xmax\"].values\n",
    "        ymaxs = image_data[\"ymax\"].values\n",
    "        boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n",
    "        areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        image_id = torch.tensor([idx])\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = areas\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n",
    "            img = transformed[\"image\"]\n",
    "            target[\"boxes\"] = torch.as_tensor(transformed[\"bboxes\"],dtype=torch.float32)\n",
    "        return torch.as_tensor(img, dtype=torch.float32), target\n",
    "    def get_height_and_width(self, image):\n",
    "        image_data = self.df.loc[self.df['filename'] == image]\n",
    "        return image_data[\"width\"].values[0], image_data[\"height\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining augmentations and transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    ToTensorV2(p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = A.Compose([\n",
    "    ToTensorV2(p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function called after we get data from data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initiating datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AnimalDataset(train_csv, train_images, categories, transform_train)\n",
    "test_dataset = AnimalDataset(test_csv, test_images, categories, transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating dataloaders from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=4, shuffle=True, num_workers=4,\n",
    "        collate_fn=collate_fn)\n",
    "    \n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting images from dataloader and verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, targets):\n",
    "    for image, target in zip(images, targets):\n",
    "        sample = image.permute(1,2,0).cpu().numpy()\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        boxes = target[\"boxes\"].cpu().numpy().astype(np.int32)\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(sample,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (220, 0, 0), 3)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(data_loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(images, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading faster rcnn model from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing classification head for fine-tuning based on our dataset including background class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = detection_model.roi_heads.box_predictor.cls_score.in_features\n",
    "detection_model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model to gpu or cpu based on device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and validating model in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, epochs=10):\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(detection_model, data_loader_train, data_loader_test, epochs=10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving model state for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(detection_model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
