{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ddd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.nn.functional.normalize(torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d918a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_validate,StratifiedKFold\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE,ADASYN,SMOTENC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def inference_sbert(sentences):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings\n",
    "\n",
    "def model(df_train,df_test,embeddings_=False,tfidf_=False,model=SVC(**{'C':4.238})):\n",
    "    \n",
    "    y_train = df_train['Domain']\n",
    "    embeddings = np.array(list(df_train['embeddings'].values))\n",
    "    smote=SMOTE(k_neighbors=1,random_state = 101)\n",
    "    embeddings, y_train = smote.fit_resample(embeddings, y_train)\n",
    "    embeddings_test = np.array(list(df_test['embeddings'].values))\n",
    "    \n",
    "    if embeddings_ == True and tfidf_==True:\n",
    "        x_train = df_train['Title_lowered']\n",
    "        x_test = df_test['Title_lowered']\n",
    "        tfidf = TfidfVectorizer(stop_words=stops,ngram_range=(1,3),max_features=900)\n",
    "        x_train_f = tfidf.fit_transform(x_train.values)\n",
    "        x_test_f = tfidf.fit_transform(x_test.values)\n",
    "        x_to_train = np.hstack((embeddings,x_train_f.todense()))\n",
    "        x_to_test = np.hstack((embeddings_test,x_test_f.todense()))\n",
    "    if embeddings_ == False and tfidf_ == True:\n",
    "        x_train = df_train['Title_lowered']\n",
    "        x_test = df_test['Title_lowered']\n",
    "        tfidf = TfidfVectorizer(stop_words=stops,ngram_range=(1,3),max_features=900)\n",
    "        x_train_f = tfidf.fit_transform(x_train.values)\n",
    "        x_test_f = tfidf.fit_transform(x_test.values)\n",
    "        x_to_train=x_train_f\n",
    "        x_to_test=x_test_f\n",
    "    if embeddings_ == True and tfidf_ == False:\n",
    "        x_to_train = embeddings\n",
    "        x_to_test = embeddings_test\n",
    "    model.fit(x_to_train, y_train)\n",
    "    y_preds = model.predict(x_to_test)\n",
    "    return y_preds,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "340a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv').sample(frac=1).drop_duplicates('Title')\n",
    "df_train['Title_lowered'] = df_train['Title'].map(lambda text : str(text).lower())\n",
    "\n",
    "sentences_train = df_train['Title'].map(str).values.tolist()\n",
    "sentences_embeddings = inference_sbert(sentences_train)\n",
    "df_train['embeddings'] = sentences_embeddings.numpy().tolist()\n",
    "#sentences_test = df_test['Title'].map(str).values.tolist()\n",
    "#sentences_embeddings = inference_sbert(sentences_test)\n",
    "#df_test['embeddings'] = sentences_embeddings.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c82cce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Title_lowered'] = df_train['Title'].map(lambda text : str(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "be46d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "03316a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "65a95951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7301fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "03023efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4829542106007931 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48099777720929865 0.0019564333914944276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48143913160259877 0.0017150340554073335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4794727047166948 0.0037157112981531792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481674943334904 0.0055176650937789114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4820700340709101 0.005113805515886498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48323657395542907 0.0055299222910731635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48379849704460426 0.00538217784769154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48401948748721807 0.0051127178565457095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48354753455532756 0.005052776624971466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48382596027028446 0.00489742801590791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48375620641909123 0.00469463410048134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48323424979658947 0.004859372480138725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4827203233444095 0.005035909792899095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4831484082969812 0.0051220395467748816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48305999848807574 0.004971199851491167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4829638247118525 0.004838090793343752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4827267961499088 0.004802273419416587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830815798264145 0.004910573866347949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48299454876003567 0.004801245946189585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48284217496606857 0.004734828992803614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4829361696875404 0.004645978177432783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830500771397792 0.00457515879618839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4828340704443519 0.004597071091471188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4826455756855223 0.00459787632432501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4824960566521391 0.004570149926922116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4823922806713113 0.004515828893456392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48234791874139066 0.004440443106786485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4822469339021765 0.004395811897951201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48210666476660846 0.004387441659497521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48197500730651915 0.004375922605710374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4816853176395759 0.0045991113288834165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4817488264602726 0.004543118804396037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4816090070914517 0.0045473073126568835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4815972117969347 0.004482402711980064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48146002575835556 0.004493609363742525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48139465597617853 0.00444978838767692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4811570703637973 0.0046225624921137735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48127376523665977 0.004619270153531952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48128395953403497 0.004561608088907728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_indexes= []\n",
    "test_indexes = []\n",
    "best_models = []\n",
    "maximums = []\n",
    "means = []\n",
    "for i in range(40):\n",
    "    mean = []\n",
    "    maximum = 0\n",
    "    y_preds_class = None\n",
    "    df_train['Domain_{}'.format(i)] = None\n",
    "    skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=np.random.randint(9,999))\n",
    "    for train_index, test_index in tqdm(skf.split(df_train['embeddings'], df_train['Domain'])):\n",
    "        dftrain, dftest = df_train.iloc[train_index], df_train.iloc[test_index]\n",
    "        dftest_,modell = model(dftrain,dftest,embeddings_=True,tfidf_=False,model=GaussianNB())\n",
    "\n",
    "        if not isinstance(y_preds_class,type(dftest_)):\n",
    "            ypro_test = dftest['Domain'].values\n",
    "            y_preds_class= dftest_\n",
    "        else:\n",
    "            ypro_test = np.concatenate((ypro_test,dftest['Domain'].values))\n",
    "            y_preds_class = np.concatenate((y_preds_class,dftest_))\n",
    "        df_train.loc[test_index,'Domain_{}'.format(i)] = dftest_\n",
    "        f1_macro = classification_report(dftest['Domain'].values,dftest_,output_dict='csv')['macro avg']['f1-score']\n",
    "        mean.append(f1_macro)\n",
    "        if f1_macro>maximum:\n",
    "            maximum = f1_macro\n",
    "            ypro_test_ = dftest['Domain'].values\n",
    "            train_indexes_ =train_index\n",
    "            test_indexes_ = test_index\n",
    "            best_modell = modell\n",
    "    means.append(np.mean(mean))\n",
    "    print(np.mean(means),np.std(means))\n",
    "    best_models.append(best_modell)\n",
    "    train_indexes.append(train_indexes_)\n",
    "    test_indexes.append(test_indexes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ceec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b496bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "98fff452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:04,  8.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def inference(model,dftest):\n",
    "    embeddings_test = np.array(list(dftest['embeddings'].values))\n",
    "    preds = model.predict_proba(embeddings_test)\n",
    "    return preds\n",
    "\n",
    "y_preds_class = None\n",
    "liste_ = []\n",
    "for index,model in tqdm(enumerate(best_models)):\n",
    "    dftrain, dftest = _, df_train\n",
    "    preds = inference(model,dftest)\n",
    "    if not isinstance(y_preds_class,type(preds)):\n",
    "        ypro_test = dftest['Domain'].values\n",
    "        y_preds_class= preds\n",
    "    else:\n",
    "        ypro_test = np.concatenate((ypro_test,dftest['Domain'].values))\n",
    "        y_preds_class = np.concatenate((y_preds_class,preds))\n",
    "    liste_.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "21b9b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2ca16f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:00<00:00, 14337.26it/s]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in tqdm(range(3835)):\n",
    "    listesqg = []\n",
    "    for j in liste_:\n",
    "        listesqg+=list(j[i])\n",
    "    features.append(listesqg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "26cf56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(scale_pos_weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4e518c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['features'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a9a8e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:03:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:03:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(features,df_train['Domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "eed218b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_.csv')\n",
    "df_test['Title_lowered'] = df_test['Title'].map(lambda text : str(text).lower())\n",
    "sentences_test = df_test['Title'].map(str).values.tolist()\n",
    "sentences_embeddings = inference_sbert(sentences_test)\n",
    "df_test['embeddings'] = sentences_embeddings.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4ec4010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:02, 18.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def inference(model,dftest):\n",
    "    embeddings_test = np.array(list(dftest['embeddings'].values))\n",
    "    preds = model.predict_proba(embeddings_test)\n",
    "    return preds\n",
    "\n",
    "y_preds_class = []\n",
    "for index,model in tqdm(enumerate(best_models)):\n",
    "    dftest = df_test\n",
    "    preds = inference(model,dftest)\n",
    "    y_preds_class.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b2e9cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d194c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1649/1649 [00:00<00:00, 13612.78it/s]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in tqdm(range(len(y_preds_class[0]))):\n",
    "    listesqg = []\n",
    "    for j in y_preds_class:\n",
    "        listesqg+=list(j[i])\n",
    "    features.append(listesqg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "61cdf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "29f219b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['labels_preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cc6bda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['ID','labels_preds']].reset_index()[['ID','labels_preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "10701fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('data/sample_submission_.csv')[['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d4e591bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.merge(df_test, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "67fb3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.merge(df_train, on='ID', how='left')#.to_csv('sample_submission_1.csv',columns=['ID','Domain'])\n",
    "df_sample = df_sample[['ID','labels_preds']]\n",
    "df_sample.columns= ['ID','Domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3705b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['Domain'] = df_sample['Domain'].map(str)\n",
    "df_sample['Domain'] = df_sample['Domain'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "44e4d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('sample_submission_23.csv',columns=['ID','Domain'],index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
